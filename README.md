
# Course Completion Prediction & Student Performance Analysis

![Python](https://img.shields.io/badge/Python-3.8%2B-blue)
![PyTorch](https://img.shields.io/badge/PyTorch-2.0%2B-red)
![TensorFlow](https://img.shields.io/badge/TensorFlow-2.0%2B-orange)
![Scikit-Learn](https://img.shields.io/badge/Scikit--Learn-Latest-yellow)

## AperÃ§u du Projet
Ce projet utilise des techniques de **Machine Learning** et **Deep Learning** pour analyser et prÃ©dire la rÃ©ussite des Ã©tudiants dans un cours en ligne.

<p align="center">
  <a href="https://votre-app-streamlit.streamlit.app/">
    <img src="https://img.shields.io/badge/Live_Demo-AccÃ©der_au_Dashboard-FF4B4B?style=for-the-badge&logo=streamlit&logoColor=white" alt="Live Demo" />
  </a>
</p>

<p align="center">
  <img src="reports/dashboard_demo.gif" width="90%" />
</p>
<p align="center"><i>DÃ©mo : Interface interactive de prÃ©diction (Streamlit).</i></p>

### Analyse des DonnÃ©es

<p align="center">
  <img src="reports/figures/final_data_analysis.png" width="90%" />
</p>
<p align="center"><i>Visualisation des corrÃ©lations : Impact direct sur la rÃ©ussite (gauche) et relations multi-variables (droite).</i></p>

---

## RÃ©sultats ClÃ©s (Test Set)

### Classification (Target: `Completed`)
Le problÃ¨me est difficile (bruitÃ©), mais les modÃ¨les surpassent la baseline alÃ©atoire.

<p align="center">
  <img src="reports/figures/final_accuracy_comparison.png" width="70%" />
</p>

| ModÃ¨le | Accuracy | F1-Score | Observations |
| :--- | :---: | :---: | :--- |
| **Baseline (Dummy)** | 49.87% | - | Performance alÃ©atoire. |
| **Logistic Regression** | 56.40% | - | Simple mais efficace. |
| **Random Forest** | 59.40% | - | Capture les interactions complexes. |
| **Gradient Boosting** | **60.47%** | - | TrÃ¨s performant, capture des non-linÃ©aritÃ©s. |
| **PyTorch NN** | 60.02% | 0.61 | Bonnes performances, mais nÃ©cessite plus de tuning. |

<p align="center">
  <img src="reports/figures/final_classification.png" width="90%" />
</p>
<p align="center"><i>Performance du modÃ¨le Deep Learning : Matrice de confusion et impact des variables (SHAP).</i></p>

### RÃ©gression (Multi-output)
Nous avons utilisÃ© des rÃ©seaux de neurones (PyTorch/TensorFlow) pour prÃ©dire les 4 variables simultanÃ©ment.

<p align="center">
  <img src="reports/figures/sklearn_rmse_comparison.png" width="70%" />
</p>

| Target | RMSE (PyTorch) | RÂ² | InterprÃ©tation |
| :--- | :---: | :---: | :--- |
| **Project Grade** | **3.56** | **0.94** | **Excellente prÃ©diction**. Les features (quiz, activitÃ©) expliquent trÃ¨s bien la note finale. |
| **Quiz Score** | 12.31 | 0.04 | Difficile Ã  prÃ©dire prÃ©cisÃ©ment uniquement via le comportement. |
| **Satisfaction** | 0.70 | ~0.00 | Aucune corrÃ©lation trouvÃ©e (probablement subjectif/alÃ©atoire). |
| **Time Spent** | 3.82 | ~0.00 | Aucune corrÃ©lation trouvÃ©e avec les features disponibles. |

<p align="center">
  <img src="reports/figures/final_regression.png" width="90%" />
</p>
<p align="center"><i>Diagnostic de la rÃ©gression : PrÃ©dictions sur les notes de projet et importance des features.</i></p>

---

## Analyses ClÃ©s
*   **Engagement**: Les Ã©tudiants ayant complÃ©tÃ© le projet final ont 90% plus de chances de rÃ©ussir le cours.
*   **Comportement**: Le temps passÃ© sur le cours est moins prÃ©dictif que la performance aux tests intermÃ©diaires.
*   **Robustesse**: Le Gradient Boosting reste le modÃ¨le de rÃ©fÃ©rence pour les donnÃ©es structurÃ©es de ce type.

---

## Installation & Usage

1.  **Cloner le repo** :
    ```bash
    git clone https://github.com/votre-username/course-completion-prediction.git
    cd course-completion-prediction
    ```

2.  **Installer les dÃ©pendances** :
    ```bash
    pip install -r requirements.txt
    ```

3.  **Lancer le pipeline complet** :
    ```bash
    python main.py
    ```
    *Ce script exÃ©cute automatiquement la prÃ©paration des donnÃ©es, les modÃ¨les de base, Scikit-Learn, PyTorch et l'analyse finale.*

4.  **Explorer les Analyses** :
    Consultez le dossier `notebooks/` pour accÃ©der aux 6 Ã©tapes dÃ©taillÃ©es du projet (EDA, SHAP values, importance des features, etc.).

5.  **ExÃ©cuter les Tests** :
    ```bash
    pytest
    ```

### ğŸš€ Interface & DÃ©ploiement

Le projet est optimisÃ© pour un dÃ©ploiement rapide et gratuit :

1.  **Dashboard Streamlit (Stand-alone)** :
    L'interface gÃ¨re dÃ©sormais l'infÃ©rence localement, ce qui permet de l'hÃ©berger sans serveur externe.
    ```bash
    python -m streamlit run streamlit_app.py
    ```

2.  **API d'InfÃ©rence (FastAPI)** :
    Toujours disponible pour une utilisation programmatique ou pour montrer vos compÃ©tences en backend.
    ```bash
    uvicorn app:app --reload
    ```
    AccÃ¨s Swagger UI : `http://127.0.0.1:8000/docs`

### IntÃ©gration Continue (CI/CD)
Le projet utilise **GitHub Actions** pour garantir la qualitÃ© du code. Ã€ chaque modification (push), un pipeline automatique :
1. Installe l'environnement.
2. ExÃ©cute le pipeline complet (`main.py`).
3. Lance les tests unitaires (`pytest`).

### Option 2 : Docker (RecommandÃ© pour la portabilitÃ©)
Si vous avez Docker installÃ©, vous pouvez lancer le projet complet sans installer Python localement :
```bash
# Construire l'image
docker build -t ml-course-prediction .

# Lancer le pipeline complet
docker run ml-course-prediction
```

## Structure du Projet
```
â”œâ”€â”€ data/                      # DonnÃ©es brutes et traitÃ©es
â”œâ”€â”€ models/                    # ModÃ¨les sauvegardÃ©s (.pth)
â”‚   â”œâ”€â”€ torch_clf_model.pth
â”‚   â”œâ”€â”€ torch_reg_model.pth
â”œâ”€â”€ notebooks/                 # Notebooks Jupyter (Exploration & Analyse)
â”‚   â”œâ”€â”€ 00_data_prep.ipynb
â”‚   â”œâ”€â”€ 01_baselines.ipynb
â”‚   â”œâ”€â”€ 02_sklearn_models.ipynb
â”‚   â”œâ”€â”€ 03_tf_models.ipynb
â”‚   â”œâ”€â”€ 04_torch_models.ipynb
â”‚   â””â”€â”€ 05_model_analysis.ipynb
â”œâ”€â”€ reports/figures/           # Graphiques gÃ©nÃ©rÃ©s pour le README
â”œâ”€â”€ src/                       # Scripts Python modulaires (Production)
â”‚   â”œâ”€â”€ 00_data_prep.py        # Nettoyage & Feature Engineering
â”‚   â”œâ”€â”€ 01_baselines.py        # ModÃ¨les de base
â”‚   â”œâ”€â”€ 02_sklearn_models.py   # ModÃ¨les Scikit-Learn
â”‚   â”œâ”€â”€ 03_tf_models.py        # ImplÃ©mentation TensorFlow
â”‚   â”œâ”€â”€ 04_torch_models.py     # ImplÃ©mentation PyTorch
â”‚   â””â”€â”€ 05_model_analysis.py   # Analyse des rÃ©sultats & SHAP
â”œâ”€â”€ tests/                     # Tests unitaires (Pytest)
â”‚   â”œâ”€â”€ test_data.py           # Validation des donnÃ©es traitÃ©es
â”‚   â””â”€â”€ test_models.py         # Validation de l'intÃ©gritÃ© des modÃ¨les
â”œâ”€â”€ .github/workflows/         # Configuration GitHub Actions (CI/CD)
â”œâ”€â”€ main.py                    # Script d'orchestration (Point d'entrÃ©e)
â”œâ”€â”€ app.py                     # Serveur d'infÃ©rence FastAPI
â”œâ”€â”€ streamlit_app.py           # Dashboard de visualisation
â”œâ”€â”€ requirements.txt           # DÃ©pendances du projet
â”œâ”€â”€ Dockerfile                 # Configuration Docker
â”œâ”€â”€ .dockerignore              # Fichiers Ã  ignorer par Docker
â””â”€â”€ README.md                  # Documentation
```

## Impact MÃ©tier & StratÃ©gie
- **Intervention PrÃ©coce** : Comme le `Project_Grade` est trÃ¨s prÃ©visible, nous pouvons identifier tÃ´t les Ã©tudiants Ã  risque d'Ã©chec et leur proposer du tutorat.
- **Engagement** : Le temps passÃ© (`Time_Spent`) n'est pas corrÃ©lÃ© Ã  la rÃ©ussite dans ce dataset, suggÃ©rant que la *qualitÃ©* de l'Ã©tude prime sur la *quantitÃ©*.
