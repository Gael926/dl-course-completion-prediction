{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.preprocessing import StandardScaler\n",
                "from sklearn.linear_model import LinearRegression\n",
                "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor, GradientBoostingClassifier, GradientBoostingRegressor\n",
                "from sklearn.multioutput import MultiOutputRegressor\n",
                "from sklearn.neural_network import MLPClassifier\n",
                "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
                "from sklearn.metrics import mean_squared_error, r2_score"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ==========================================\n",
                "# 1. Chargement des données\n",
                "# ==========================================\n",
                "\n",
                "# Classification\n",
                "try:\n",
                "    X_class = pd.read_csv('../data/processed/X_classification.csv')\n",
                "    y_class = pd.read_csv('../data/processed/y_classification.csv')\n",
                "    # Régression\n",
                "    X_reg = pd.read_csv('../data/processed/X_regression.csv')\n",
                "    y_reg = pd.read_csv('../data/processed/y_regression.csv')\n",
                "    \n",
                "    print(\"Données chargées avec succès.\")\n",
                "    print(f\"  Classification: {X_class.shape}\")\n",
                "    print(f\"  Régression: {X_reg.shape}\")\n",
                "\n",
                "except FileNotFoundError:\n",
                "    print(\"Erreur: Fichiers non trouvés. Vérifiez le chemin '../data/processed/'.\")\n",
                "    # Pour le test, on arrête si pas de données, sinon le reste plantera\n",
                "    exit()\n",
                "\n",
                "# Définition des noms des cibles pour la régression (utile pour l'affichage plus bas)\n",
                "target_names = ['Quiz_Score_Avg', 'Project_Grade', 'Satisfaction_Rating', 'Time_Spent_Hours']"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ==========================================\n",
                "# PARTIE 1: CLASSIFICATION (Modèles Avancés)\n",
                "# Objectif: Prédire la complétion du cours (0/1)\n",
                "# ==========================================\n",
                "print(\"\\n\" + \"=\"*40)\n",
                "print(\" PARTIE 1: CLASSIFICATION (Modèles Avancés)\")\n",
                "print(\"=\"*40)\n",
                "\n",
                "# Split train/test (80% train, 20% test)\n",
                "X_train_class, X_test_class, y_train_class, y_test_class = train_test_split(\n",
                "    X_class, y_class, test_size=0.2, random_state=42\n",
                ")\n",
                "\n",
                "# Raveler y pour sklearn (attend un vecteur 1D)\n",
                "y_train_class = y_train_class.values.ravel()\n",
                "y_test_class = y_test_class.values.ravel()\n",
                "\n",
                "# Normalisation\n",
                "scaler_class = StandardScaler()\n",
                "X_train_class_scaled = scaler_class.fit_transform(X_train_class)\n",
                "X_test_class_scaled = scaler_class.transform(X_test_class)\n",
                "\n",
                "# --- A. Random Forest Classifier ---\n",
                "rf_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
                "rf_clf.fit(X_train_class_scaled, y_train_class)\n",
                "y_pred_rf = rf_clf.predict(X_test_class_scaled)\n",
                "acc_rf = accuracy_score(y_test_class, y_pred_rf)\n",
                "print(f\"Random Forest Accuracy:     {acc_rf:.4f}\")\n",
                "\n",
                "# --- B. MLP Classifier (Réseau de Neurones) ---\n",
                "mlp_clf = MLPClassifier(hidden_layer_sizes=(64, 32), activation='relu', solver='adam', max_iter=500, random_state=42)\n",
                "mlp_clf.fit(X_train_class_scaled, y_train_class)\n",
                "y_pred_mlp = mlp_clf.predict(X_test_class_scaled)\n",
                "acc_mlp = accuracy_score(y_test_class, y_pred_mlp)\n",
                "print(f\"MLP Classifier Accuracy:      {acc_mlp:.4f}\")\n",
                "\n",
                "# --- C. Gradient Boosting Classifier (XGBoost-like) ---\n",
                "gb_clf = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)\n",
                "gb_clf.fit(X_train_class_scaled, y_train_class)\n",
                "y_pred_gb = gb_clf.predict(X_test_class_scaled)\n",
                "acc_gb = accuracy_score(y_test_class, y_pred_gb)\n",
                "print(f\"Gradient Boosting Accuracy:   {acc_gb:.4f}\")\n",
                "\n",
                "print(\"\\nConfusion Matrix (Random Forest):\")\n",
                "print(confusion_matrix(y_test_class, y_pred_rf))\n",
                "\n",
                "# Visualisation Comparaison\n",
                "models = ['RandomForest', 'MLP', 'GradBoost']\n",
                "accuracies = [acc_rf, acc_mlp, acc_gb]\n",
                "colors = ['#3498db', '#9b59b6', '#e67e22']\n",
                "\n",
                "plt.figure(figsize=(10, 6))\n",
                "bars = plt.bar(models, accuracies, color=colors)\n",
                "plt.ylim(0.4, 0.7)\n",
                "plt.title('Comparaison Modèles Avancés')\n",
                "plt.ylabel('Accuracy')\n",
                "\n",
                "# Add value labels\n",
                "for bar in bars:\n",
                "    height = bar.get_height()\n",
                "    plt.text(bar.get_x() + bar.get_width()/2., height,\n",
                "             f'{height:.4f}',\n",
                "             ha='center', va='bottom')\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ==========================================\n",
                "# PARTIE 2: REGRESSION\n",
                "# Objectif: Prédire 4 variables continues\n",
                "# ==========================================\n",
                "print(\"\\n\" + \"=\"*40)\n",
                "print(\" PARTIE 2: REGRESSION (Le Diagnostic)\")\n",
                "print(\"=\"*40)\n",
                "\n",
                "# Split train/test\n",
                "X_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(\n",
                "    X_reg, y_reg, test_size=0.2, random_state=42\n",
                ")\n",
                "\n",
                "# Normalisation X\n",
                "scaler_X_reg = StandardScaler()\n",
                "X_train_reg_scaled = scaler_X_reg.fit_transform(X_train_reg)\n",
                "X_test_reg_scaled = scaler_X_reg.transform(X_test_reg)\n",
                "\n",
                "# Normalisation y (Crucial pour comparaison PyTorch)\n",
                "scaler_y_reg = StandardScaler()\n",
                "y_train_reg_scaled = scaler_y_reg.fit_transform(y_train_reg)\n",
                "y_test_reg_scaled = scaler_y_reg.transform(y_test_reg)\n",
                "\n",
                "# --- A. Régression Linéaire (Le Juge de Paix) ---\n",
                "lin_reg = LinearRegression()\n",
                "lin_reg.fit(X_train_reg_scaled, y_train_reg_scaled)\n",
                "\n",
                "# Prédiction et Inversion\n",
                "y_pred_lin_scaled = lin_reg.predict(X_test_reg_scaled)\n",
                "y_pred_lin = scaler_y_reg.inverse_transform(y_pred_lin_scaled)\n",
                "y_test_reg_inv = scaler_y_reg.inverse_transform(y_test_reg_scaled)\n",
                "\n",
                "rmse_lin_global = np.sqrt(mean_squared_error(y_test_reg_inv, y_pred_lin))\n",
                "\n",
                "print(f\"Linear Regression GLOBAL RMSE: {rmse_lin_global:.4f}\")\n",
                "print(\"-\" * 30)\n",
                "print(\"Détail par variable (LINEAR REGRESSION) :\")\n",
                "for i, name in enumerate(target_names):\n",
                "    rmse = np.sqrt(mean_squared_error(y_test_reg_inv[:, i], y_pred_lin[:, i]))\n",
                "    r2 = r2_score(y_test_reg_inv[:, i], y_pred_lin[:, i])\n",
                "    flag = \"SUCCES\" if r2 > 0.8 else \"FAIBLE\"\n",
                "    print(f\"  {name:<20} | RMSE: {rmse:.4f} | R²: {r2:.4f} {flag}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# --- B. Random Forest Regressor ---\n",
                "rf_reg = RandomForestRegressor(n_estimators=50, random_state=42, n_jobs=-1)\n",
                "rf_reg.fit(X_train_reg_scaled, y_train_reg_scaled)\n",
                "\n",
                "# Prédiction et Inversion\n",
                "y_pred_rf_scaled = rf_reg.predict(X_test_reg_scaled)\n",
                "y_pred_rf_reg = scaler_y_reg.inverse_transform(y_pred_rf_scaled)\n",
                "\n",
                "rmse_rf_global = np.sqrt(mean_squared_error(y_test_reg_inv, y_pred_rf_reg))\n",
                "\n",
                "print(\"\\n\" + \"-\" * 60)\n",
                "print(f\"Random Forest GLOBAL RMSE:     {rmse_rf_global:.4f}\")\n",
                "print(\"-\" * 30)\n",
                "print(\"Détail par variable (RANDOM FOREST) :\")\n",
                "for i, name in enumerate(target_names):\n",
                "    rmse = np.sqrt(mean_squared_error(y_test_reg_inv[:, i], y_pred_rf_reg[:, i]))\n",
                "    r2 = r2_score(y_test_reg_inv[:, i], y_pred_rf_reg[:, i])\n",
                "    flag = \"SUCCES\" if r2 > 0.8 else \"FAIBLE\"\n",
                "    print(f\"  {name:<20} | RMSE: {rmse:.4f} | R²: {r2:.4f} {flag}\")\n",
                "\n",
                "# --- C. Gradient Boosting Regressor (Amélioration) ---\n",
                "# Note: GradientBoostingRegressor ne supporte pas le multi-output nativement, on utilise MultiOutputRegressor\n",
                "gb_reg = MultiOutputRegressor(GradientBoostingRegressor(n_estimators=100, random_state=42))\n",
                "gb_reg.fit(X_train_reg_scaled, y_train_reg_scaled)\n",
                "\n",
                "# Prédiction et Inversion\n",
                "y_pred_gb_scaled = gb_reg.predict(X_test_reg_scaled)\n",
                "y_pred_gb_reg = scaler_y_reg.inverse_transform(y_pred_gb_scaled)\n",
                "\n",
                "rmse_gb_global = np.sqrt(mean_squared_error(y_test_reg_inv, y_pred_gb_reg))\n",
                "\n",
                "print(\"\\n\" + \"-\" * 60)\n",
                "print(f\"Gradient Boosting GLOBAL RMSE: {rmse_gb_global:.4f}\")\n",
                "print(\"-\" * 30)\n",
                "print(\"Détail par variable (GRADIENT BOOSTING) :\")\n",
                "for i, name in enumerate(target_names):\n",
                "    rmse = np.sqrt(mean_squared_error(y_test_reg_inv[:, i], y_pred_gb_reg[:, i]))\n",
                "    r2 = r2_score(y_test_reg_inv[:, i], y_pred_gb_reg[:, i])\n",
                "    flag = \"SUCCES\" if r2 > 0.8 else \"FAIBLE\"\n",
                "    print(f\"  {name:<20} | RMSE: {rmse:.4f} | R²: {r2:.4f} {flag}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ==========================================\n",
                "# 3. Visualisation Comparative (Project_Grade)\n",
                "# ==========================================\n",
                "print(\"\\nAffichage du graphique pour Project_Grade...\")\n",
                "\n",
                "idx = 1 # Index de Project_Grade\n",
                "name = target_names[idx]\n",
                "\n",
                "plt.figure(figsize=(14, 6))\n",
                "\n",
                "# Plot 1: Linear Regression\n",
                "plt.subplot(1, 2, 1)\n",
                "plt.scatter(y_test_reg_inv[:, idx], y_pred_lin[:, idx], alpha=0.4, color='green', label='Predictions')\n",
                "# Ligne idéale\n",
                "min_val = y_test_reg_inv[:, idx].min()\n",
                "max_val = y_test_reg_inv[:, idx].max()\n",
                "plt.plot([min_val, max_val], [min_val, max_val], 'r--', lw=2, label='Parfait (Idéal)')\n",
                "plt.title(f'Linear Regression: {name}\\n(Si aligné = Relation Linéaire)')\n",
                "plt.xlabel('Vraies Notes')\n",
                "plt.ylabel('Prédictions')\n",
                "plt.legend()\n",
                "plt.grid(True, alpha=0.3)\n",
                "\n",
                "# Plot 2: Random Forest\n",
                "plt.subplot(1, 2, 2)\n",
                "plt.scatter(y_test_reg_inv[:, idx], y_pred_rf_reg[:, idx], alpha=0.4, color='blue', label='Predictions')\n",
                "plt.plot([min_val, max_val], [min_val, max_val], 'r--', lw=2, label='Parfait (Idéal)')\n",
                "plt.title(f'Random Forest: {name}\\n(Si nuage dispersé = Difficulté)')\n",
                "plt.xlabel('Vraies Notes')\n",
                "plt.ylabel('Prédictions')\n",
                "plt.legend()\n",
                "plt.grid(True, alpha=0.3)\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()\n",
                "\n",
                "# Comparaison des RMSE globaux\n",
                "models_reg = ['Linear', 'RandomForest', 'GradientBoosting']\n",
                "rmses_reg = [rmse_lin_global, rmse_rf_global, rmse_gb_global]\n",
                "colors_reg = ['#2ecc71', '#3498db', '#e67e22']\n",
                "\n",
                "plt.figure(figsize=(8, 5))\n",
                "bars = plt.bar(models_reg, rmses_reg, color=colors_reg)\n",
                "plt.title('Comparaison RMSE Global (Plus bas est meilleur)')\n",
                "plt.ylabel('RMSE Global')\n",
                "\n",
                "for bar in bars:\n",
                "    height = bar.get_height()\n",
                "    plt.text(bar.get_x() + bar.get_width()/2., height,\n",
                "             f'{height:.4f}',\n",
                "             ha='center', va='bottom')\n",
                "plt.show()"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.10"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}