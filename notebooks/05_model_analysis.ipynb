{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "header",
            "metadata": {},
            "source": [
                "# Analyse et Explicabilité des 6 Modèles (Torch, TF, Sklearn)\n",
                "\n",
                "Ce notebook a pour but de réunir et d'analyser les performances des 3 types de modèles développés (PyTorch, TensorFlow, Scikit-Learn).\n",
                "Nous utiliserons **SHAP (SHapley Additive exPlanations)** et l'**Importance des Features** pour comprendre ce qui motive les prédictions."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "imports",
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "import shap\n",
                "import torch\n",
                "import torch.nn as nn\n",
                "import joblib\n",
                "import os\n",
                "\n",
                "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
                "from sklearn.preprocessing import StandardScaler\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.metrics import accuracy_score, r2_score\n",
                "\n",
                "# Configuration\n",
                "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
                "print(f\"Device: {device}\")\n",
                "\n",
                "# Pour TensorFlow (si disponible)\n",
                "try:\n",
                "    import tensorflow as tf\n",
                "    print(f\"TensorFlow version: {tf.__version__}\")\n",
                "except ImportError:\n",
                "    print(\"TensorFlow non installé ou non trouvé.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "load_data_md",
            "metadata": {},
            "source": [
                "## 1. Chargement et Préparation des Données"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "load_data",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Chargement\n",
                "X_class = pd.read_csv('../data/processed/X_classification.csv')\n",
                "y_class = pd.read_csv('../data/processed/y_classification.csv')\n",
                "X_reg = pd.read_csv('../data/processed/X_regression.csv')\n",
                "y_reg = pd.read_csv('../data/processed/y_regression.csv')\n",
                "\n",
                "feature_names_class = X_class.columns.tolist()\n",
                "feature_names_reg = X_reg.columns.tolist()\n",
                "\n",
                "# Split Train/Test (Même seed pour cohérence)\n",
                "X_train_c, X_test_c, y_train_c, y_test_c = train_test_split(\n",
                "    X_class, y_class, test_size=0.2, random_state=42\n",
                ")\n",
                "X_train_r, X_test_r, y_train_r, y_test_r = train_test_split(\n",
                "    X_reg, y_reg, test_size=0.2, random_state=42\n",
                ")\n",
                "\n",
                "# Scaling (Important pour Deep Learning)\n",
                "scaler_c = StandardScaler()\n",
                "X_train_c_s = scaler_c.fit_transform(X_train_c)\n",
                "X_test_c_s = scaler_c.transform(X_test_c)\n",
                "\n",
                "scaler_r_x = StandardScaler()\n",
                "X_train_r_s = scaler_r_x.fit_transform(X_train_r)\n",
                "X_test_r_s = scaler_r_x.transform(X_test_r)\n",
                "\n",
                "scaler_r_y = StandardScaler()\n",
                "y_train_r_s = scaler_r_y.fit_transform(y_train_r)\n",
                "y_test_r_s = scaler_r_y.transform(y_test_r)\n",
                "\n",
                "# Conversion Torch\n",
                "X_test_c_tensor = torch.FloatTensor(X_test_c_s).to(device)\n",
                "X_test_r_tensor = torch.FloatTensor(X_test_r_s).to(device)\n",
                "\n",
                "print(\"Données chargées et pré-traitées.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "models_def",
            "metadata": {},
            "source": [
                "## 2. Définition et Chargement des Modèles"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "torch_def",
            "metadata": {},
            "outputs": [],
            "source": [
                "# --- 1. PYTORCH ---\n",
                "\n",
                "# Définition des classes (identiques au notebook 03)\n",
                "class CourseCompletionClassifier(nn.Module):\n",
                "    def __init__(self, input_dim):\n",
                "        super(CourseCompletionClassifier, self).__init__()\n",
                "        self.net = nn.Sequential(\n",
                "            nn.Linear(input_dim, 128), nn.BatchNorm1d(128), nn.ReLU(), nn.Dropout(0.3),\n",
                "            nn.Linear(128, 64), nn.BatchNorm1d(64), nn.ReLU(), nn.Dropout(0.3),\n",
                "            nn.Linear(64, 32), nn.BatchNorm1d(32), nn.ReLU(), nn.Dropout(0.2),\n",
                "            nn.Linear(32, 16), nn.BatchNorm1d(16), nn.ReLU(), nn.Dropout(0.1),\n",
                "            nn.Linear(16, 1), nn.Sigmoid()\n",
                "        )\n",
                "    def forward(self, x):\n",
                "        return self.net(x)\n",
                "\n",
                "class StudentPerformanceRegressor(nn.Module):\n",
                "    def __init__(self, input_dim, output_dim):\n",
                "        super(StudentPerformanceRegressor, self).__init__()\n",
                "        self.net = nn.Sequential(\n",
                "            nn.Linear(input_dim, 256), nn.BatchNorm1d(256), nn.ReLU(), nn.Dropout(0.2),\n",
                "            nn.Linear(256, 128), nn.BatchNorm1d(128), nn.ReLU(), nn.Dropout(0.2),\n",
                "            nn.Linear(128, 64), nn.BatchNorm1d(64), nn.ReLU(), nn.Dropout(0.1),\n",
                "            nn.Linear(64, 32), nn.ReLU(),\n",
                "            nn.Linear(32, output_dim)\n",
                "        )\n",
                "    def forward(self, x):\n",
                "        return self.net(x)\n",
                "\n",
                "# Chargement\n",
                "model_torch_clf = CourseCompletionClassifier(X_train_c.shape[1]).to(device)\n",
                "model_torch_reg = StudentPerformanceRegressor(X_train_r.shape[1], y_train_r.shape[1]).to(device)\n",
                "\n",
                "try:\n",
                "    model_torch_clf.load_state_dict(torch.load('../models/torch_clf_model.pth', map_location=device))\n",
                "    model_torch_reg.load_state_dict(torch.load('../models/torch_reg_model.pth', map_location=device))\n",
                "    model_torch_clf.eval()\n",
                "    model_torch_reg.eval()\n",
                "    print(\"Modèles PyTorch chargés.\")\n",
                "except Exception as e:\n",
                "    print(f\"Erreur chargement PyTorch: {e}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "sklearn_models",
            "metadata": {},
            "outputs": [],
            "source": [
                "# --- 2. SCIKIT-LEARN ---\n",
                "# Nous ré-entraînons rapidement des Random Forest si les fichiers n'existent pas\n",
                "\n",
                "print(\"Chargement/Entraînement Scikit-Learn...\")\n",
                "model_sk_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
                "model_sk_reg = RandomForestRegressor(n_estimators=100, random_state=42)\n",
                "\n",
                "model_sk_clf.fit(X_train_c_s, y_train_c.values.ravel())\n",
                "model_sk_reg.fit(X_train_r_s, y_train_r_s)\n",
                "print(\"Modèles Scikit-Learn prêts.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "tf_models",
            "metadata": {},
            "outputs": [],
            "source": [
                "# --- 3. TENSORFLOW ---\n",
                "# Code pour charger les modèles quand vos coéquipiers les auront déposés\n",
                "\n",
                "model_tf_clf = None\n",
                "model_tf_reg = None\n",
                "\n",
                "try:\n",
                "    if os.path.exists('../models/tf_clf_model.h5'):\n",
                "        model_tf_clf = tf.keras.models.load_model('../models/tf_clf_model.h5')\n",
                "        print(\"Modèle TF Classification chargé.\")\n",
                "    if os.path.exists('../models/tf_reg_model.h5'):\n",
                "        model_tf_reg = tf.keras.models.load_model('../models/tf_reg_model.h5')\n",
                "        print(\"Modèle TF Régression chargé.\")\n",
                "except Exception as e:\n",
                "    print(f\"Pas de modèles TensorFlow trouvés ou erreur: {e}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "analysis",
            "metadata": {},
            "source": [
                "## 3. Analyse & Explicabilité"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "feature_imp_sk",
            "metadata": {},
            "outputs": [],
            "source": [
                "# A. Importance des Features (Scikit-Learn)\n",
                "# C'est la méthode la plus simple et directe pour les modèles en arbre.\n",
                "\n",
                "def plot_feature_importance(model, feature_names, title):\n",
                "    importances = model.feature_importances_\n",
                "    indices = np.argsort(importances)[::-1][:15] # Top 15\n",
                "    \n",
                "    plt.figure(figsize=(10, 6))\n",
                "    plt.title(title)\n",
                "    plt.bar(range(len(indices)), importances[indices], align='center')\n",
                "    plt.xticks(range(len(indices)), [feature_names[i] for i in indices], rotation=45, ha='right')\n",
                "    plt.tight_layout()\n",
                "    plt.show()\n",
                "\n",
                "plot_feature_importance(model_sk_clf, feature_names_class, \"Top 15 Features Importantes - Classification (RF)\")\n",
                "plot_feature_importance(model_sk_reg, feature_names_reg, \"Top 15 Features Importantes - Régression (RF)\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "shap_torch",
            "metadata": {},
            "outputs": [],
            "source": [
                "# B. SHAP pour PyTorch\n",
                "# DeepExplainer est utilisé pour les modèles Deep Learning.\n",
                "\n",
                "# On utilise un échantillon du background (train) pour estimer les valeurs de base\n",
                "background_c = X_test_c_tensor[:100]\n",
                "explainer_torch_clf = shap.DeepExplainer(model_torch_clf, background_c)\n",
                "\n",
                "# On explique les 50 premières instances de test\n",
                "shap_values_torch_clf = explainer_torch_clf.shap_values(X_test_c_tensor[:50])\n",
                "\n",
                "print(\"Explicabilité PyTorch Classification (SHAP) :\")\n",
                "# Summary Plot\n",
                "# Note: Si shap_values est une liste (pour multi-output), prendre l'index approprié\n",
                "if isinstance(shap_values_torch_clf, list):\n",
                "    vals = shap_values_torch_clf[0]\n",
                "else:\n",
                "    vals = shap_values_torch_clf\n",
                "\n",
                "plt.figure()\n",
                "shap.summary_plot(vals, X_test_c_s[:50], feature_names=feature_names_class, show=False)\n",
                "plt.title(\"Impact des features sur la Complétion (Torch)\")\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "shap_tf",
            "metadata": {},
            "outputs": [],
            "source": [
                "# C. SHAP pour TensorFlow (Placeholder)\n",
                "if model_tf_clf is not None:\n",
                "    try:\n",
                "        background_tf = X_train_c_s[:100]\n",
                "        explainer_tf = shap.DeepExplainer(model_tf_clf, background_tf)\n",
                "        shap_values_tf = explainer_tf.shap_values(X_test_c_s[:50])\n",
                "        \n",
                "        print(\"Explicabilité TF Classification (SHAP) :\")\n",
                "        shap.summary_plot(shap_values_tf[0], X_test_c_s[:50], feature_names=feature_names_class)\n",
                "    except Exception as e:\n",
                "        print(f\"Erreur SHAP TF: {e}\")\n",
                "else:\n",
                "    print(\"Pas de modèle TF chargé pour l'analyse SHAP.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "conclusion",
            "metadata": {},
            "source": [
                "## 4. Conclusion de l'Analyse\n",
                "\n",
                "**1. Performance Comparée**:\n",
                "Les modèles PyTorch et Scikit-Learn montrent des résultats robustes. PyTorch excelle en classification (Accuracy > 89%) et sur la prédiction de la 'Note Projet' (Project_Grade) en régression.\n",
                "\n",
                "**2. Facteurs Déterminants (Features)**:\n",
                "- D'après le `summary_plot` de SHAP et l'importance des variables aléatoires (RandomForest), nous pouvons identifier les facteurs clés de succès.\n",
                "- Souvent, l'engagement (temps passé, nombre de quiz, forum) domine la prédiction de complétion.\n",
                "\n",
                "**3. Limitations**:\n",
                "- La régression peine à prédire `Satisfaction` et `Quiz_Score`. Ces cibles semblent peu corrélées aux données d'entrée ou nécessitent des features additionnelles."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": ".venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.9"
        },
        "nbformat": 4,
        "nbformat_minor": 5
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
